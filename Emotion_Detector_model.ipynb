{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArgSotUovIFS",
        "outputId": "d21e9841-6c98-457a-f950-3c9917a80dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d ananthu017/emotion-detection-fer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qWoXp7Gvg5S"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/emotion-detection-fer.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNZbd877vlto"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDU9MitQvlwQ",
        "outputId": "6509b15b-063d-44b3-ee3c-b42feaccd49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28709 files belonging to 7 classes.\n",
            "Found 7178 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "image_size = (160, 160)\n",
        "\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    '/content/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=16,\n",
        "    image_size=image_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.image_dataset_from_directory(\n",
        "    '/content/test',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=16,\n",
        "    image_size=image_size\n",
        ")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess).shuffle(500).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess).cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSCst9CivlzS",
        "outputId": "a8d8da50-6219-4478-a59b-ea6bf1808bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 5. Build the transfer learning model\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(160, 160, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = True  # Freeze base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVOWeBEFvl2t"
      },
      "outputs": [],
      "source": [
        "# 6. Compile model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8P3lyMNwC7I"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2s5GNMrwC-H"
      },
      "outputs": [],
      "source": [
        "# 7. Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_mobilenet_model.h5', save_best_only=True, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOUAo5PywDBj",
        "outputId": "91f63497-df9b-4ae1-9b55-b1839defa078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.6878 - loss: 0.8599 - val_accuracy: 0.5952 - val_loss: 1.2055\n",
            "Epoch 2/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 37ms/step - accuracy: 0.7022 - loss: 0.8143 - val_accuracy: 0.5715 - val_loss: 1.2865\n",
            "Epoch 3/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.7197 - loss: 0.7885 - val_accuracy: 0.6163 - val_loss: 1.2321\n",
            "Epoch 4/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 38ms/step - accuracy: 0.7303 - loss: 0.7423 - val_accuracy: 0.6115 - val_loss: 1.1874\n",
            "Epoch 5/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 38ms/step - accuracy: 0.7453 - loss: 0.7020 - val_accuracy: 0.6096 - val_loss: 1.2214\n",
            "Epoch 6/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.7666 - loss: 0.6625 - val_accuracy: 0.6116 - val_loss: 1.1997\n",
            "Epoch 7/15\n",
            "\u001b[1m1795/1795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.7770 - loss: 0.6291 - val_accuracy: 0.6290 - val_loss: 1.2351\n"
          ]
        }
      ],
      "source": [
        "# 8. Train the model\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvT0WJUswWkt"
      },
      "outputs": [],
      "source": [
        "# 9. Plot training accuracy\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('MobileNetV2 Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyNE15MAwbLL"
      },
      "outputs": [],
      "source": [
        "# 10. Final evaluation\n",
        "\n",
        "model.evaluate(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr1d31AVwipr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}